{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfZlOCtXS6M00RPUyJey/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayan-Vishwakarma/Keras-Implementation-of-Dense-and-DC-NSGAN-WGAN-WGANGP-etc/blob/main/WGAN_GP_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBd9_LoPw80F"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxR0JmPtqPD2"
      },
      "source": [
        "# WGAN_GP keras Model for faster development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUC5WYtl4x97"
      },
      "source": [
        "Only discriminator and Generator model are needed to be constructed.The model takes care of the whole WGAN_GP training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEn0sIW_qaqL"
      },
      "source": [
        "WGAN_GP -----> Subclass of Keras Model class.\n",
        "\n",
        "Requires a trainable Generator model, a trainable Discriminator model and the dimension of latent space on which generator acts.\n",
        "\n",
        "> fit() \n",
        "\n",
        ">>> Keras Model fit function that requires the images whose distribution has to be learnt.All other working are the same.\n",
        "\n",
        "**Important: Here batch_size must be equal to  (mini_batch_size x n_critic) because a given batch is divided to n_critic mini_batches on which critic is trained n_critic times.And because of this reason, the given batch_size in fit method should be divisible by n_critic for best memory utilization.\n",
        "Preffered n_critic are 2,4,8,... and mini_batch_size are 16,32,64,...  \n",
        "This poses another problem that larger images are restricted for very small mini_batch_sizes using this approach since the autograph does not seems to let outer variables use graph tensors,restricting fine grained control.However the train_step can be easily modified to take some permutations of batch_size to increase mini_batch_size.**\n",
        "\n",
        "> training_loop( xt , n_iter , batch_size , sampling_interval )\n",
        "\n",
        ">>> xt :: The numpy ndarray in which images are stored,i.e, the training dataset. shape = (N,H,W,C)\n",
        ">>>n_iter :: The no of iterations to train\n",
        ">>>batch_size :: The batch size used for training\n",
        ">>>sampling_interval :: The interval after which the images are to be sampled\n",
        ">>> return -> EM loss and GP loss after each iteration\n",
        ">> Note::Here, the training_loop returns the original loss, which fit returns the estimated EM distace,i.e.,the negative of the loss returned by training_loop.\n",
        "\n",
        "> compile( opt_gen , opt_disc , opt_GP , n_critic , lmbda=10 )\n",
        "\n",
        ">>> It requires 3 different optmizers:one for generator model, one for discriminator model for reducing EM distance and the third for discriminator for reducing gradient penalty.\n",
        "\n",
        ">>>n_critic is the number of times critic has to be trained\n",
        "\n",
        ">>>lambda is multiplied to GP_loss.\n",
        "\n",
        " ** Here 2 different optimizers are required for discriminator model.**\n",
        "> call(inputs , with_discriminator=None)\n",
        "\n",
        ">>> inputs :: The input to be given to generator.This input is derived from latent space.\n",
        "\n",
        ">>> with_discriminator :: Boolean, If true the outputs are further passed to discriminator.Only valid if discriminator exists.\n",
        "\n",
        "> RemoveDiscriminator(self):: Removes the discriminator from the model leaving behind only the generator model for generating images.Can be used when training is complete.\n",
        "\n",
        "> SampleImages(self,x,y) :: Sample images from generator. A total of x multiplied by y images are samples displayed in x rows and y columns.\n",
        "\n",
        "> EM(labels,logits) :: Estimates the EM distance given the binary label representing in which class an object belong vs the output of discriminator that best estimates the EM distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v7pC0PzJItB"
      },
      "source": [
        "Attributes:\n",
        "\n",
        "generator :: The generator model for generating images\n",
        "\n",
        "discriminator :: The critic model which estimates the EM distance between the current generator's distribution and real distribution.\n",
        "\n",
        "z_dim :: Latent space dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwMDDDY5xElp"
      },
      "source": [
        "class WGAN_GP(keras.models.Model):\n",
        " \n",
        "  def __init__(self,generator,discriminator,z_dim,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.with_disc = True\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "    self.z_dim = z_dim\n",
        "    self.gan = keras.Sequential([generator,discriminator])\n",
        "    assert ((self.gan.layers[0].trainable == True) and (self.gan.layers[1].trainable == True)),\"Generator and Discriminator should be trainable\"\n",
        "    \n",
        "  def call(self,inputs,with_discriminator=None):\n",
        "    if with_discriminator and self.with_disc:\n",
        "      return self.gan(inputs)      \n",
        "    else:\n",
        "      return self.generator(inputs)\n",
        " \n",
        "  def compile(self,opt_gen,opt_disc,opt_GP,n_critic,lmbda=10):\n",
        "    super().compile(optimizer = opt_gen,loss = self.EM)\n",
        "    self.opt_gen = opt_gen\n",
        "    self.opt_disc= opt_disc\n",
        "    self.opt_GP = opt_GP\n",
        "    self.n_critic = n_critic\n",
        "    assert ( lmbda > 0 ),\"lambda value should be strictly greater than 0\"\n",
        "    self.lmbda = lmbda\n",
        " \n",
        "  def train_step(self,imgs):\n",
        "    if isinstance(imgs,tuple):\n",
        "      imgs = data[0]\n",
        "    batch_size =  (tf.shape(imgs)[0] // self.n_critic)\n",
        "    \n",
        "    for i in range(self.n_critic):\n",
        "      x = imgs[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "      x_ = generator(tf.random.normal((batch_size,self.z_dim)))\n",
        " \n",
        "      with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "        xin = tf.concat([x,x_],axis=0)\n",
        "        yin = tf.concat([tf.ones((batch_size,1)),tf.zeros((batch_size,1))],axis = 0)\n",
        "        loss = self.EM(yin,self.discriminator(xin))\n",
        " \n",
        "      grads = tape.gradient(loss,self.discriminator.trainable_weights)#\n",
        "      self.opt_disc.apply_gradients(zip(grads,self.discriminator.trainable_weights))#\n",
        "      del xin,yin,grads\n",
        " \n",
        "      t = tf.random.uniform((batch_size,1,1,1))\n",
        "      xche = t*x + (1-t)*x_\n",
        " \n",
        "      with tf.GradientTape(watch_accessed_variables=True,persistent = True) as Tape:\n",
        "        Tape.watch(xche)\n",
        "        with tf.GradientTape(watch_accessed_variables=True,persistent=True) as tape:\n",
        "          tape.watch(xche)\n",
        "          y =  self.discriminator(xche)\n",
        "        Dx = tape.gradient(y,xche)\n",
        "        GP_loss = self.lmbda * tf.math.reduce_mean((tf.math.reduce_euclidean_norm(Dx,axis=[1,2,3]) - 1.)**2)\n",
        " \n",
        "      grads = Tape.gradient(GP_loss,self.discriminator.trainable_weights,unconnected_gradients=tf.UnconnectedGradients.ZERO)#\n",
        " \n",
        "      del tape,Tape,xche,y,Dx,x,x_\n",
        "      self.opt_GP.apply_gradients(zip(grads,self.discriminator.trainable_weights))#\n",
        " \n",
        "    with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "      xin = tf.random.normal(tf.stack([batch_size,self.z_dim],axis=0))\n",
        "      yin = tf.ones((batch_size,1))\n",
        "      gloss = self.EM(yin,self.gan(xin))\n",
        "    \n",
        "    grads = tape.gradient(gloss,self.generator.trainable_weights)\n",
        "    self.opt_gen.apply_gradients(zip(grads,self.generator.trainable_weights))\n",
        " \n",
        "    return {\"EM_Distance\":-loss,\"GP_loss\":GP_loss,\"generative_loss\":gloss}\n",
        "\n",
        "  def training_loop(self,xt,n_iter,batch_size,sampling_interval):\n",
        "    self.gan.compile( optimizer = self.opt_gen,loss = self.EM)\n",
        "    self.discriminator.compile( optimizer = self.opt_disc,loss = self.EM)\n",
        "    disc_weight = discriminator.trainable_weights\n",
        "    self.discriminator.trainable = False\n",
        "    assert self.discriminator.trainable == False\n",
        "\n",
        "    label_discriminator = np.concatenate([np.ones(batch_size),np.zeros(batch_size)],axis=0)\n",
        "    label_generator = np.ones(batch_size)\n",
        "    losses = []\n",
        "    \n",
        "    for i in range(n_iter):\n",
        "      for j in range(self.n_critic):\n",
        "          \n",
        "        x = xt[np.random.randint(len(xt),size= batch_size)]\n",
        "        x_ = self.generator(np.random.randn(batch_size,self.z_dim))\n",
        "        loss = self.discriminator.train_on_batch(np.concatenate([x,x_],axis=0),label_discriminator)\n",
        "        \n",
        "        t = tf.random.uniform((batch_size,1,1,1))\n",
        "        xche = t*x + (1-t)*x_\n",
        "        \n",
        "        with tf.GradientTape(watch_accessed_variables=True,persistent = True) as Tape:\n",
        "          xche = tf.Variable(xche)\n",
        "          Tape.watch(xche)\n",
        "          with tf.GradientTape(watch_accessed_variables=True,persistent=True) as tape:\n",
        "            tape.watch(xche)\n",
        "            y =  self.discriminator(xche)\n",
        "          Dx = tape.gradient(y,xche)\n",
        "          GP_loss = self.lmbda * tf.math.reduce_mean((tf.math.reduce_euclidean_norm(Dx,axis=[1,2,3]) - 1.)**2)\n",
        "        \n",
        "        losses.append([loss,GP_loss.numpy()])\n",
        "        grads = Tape.gradient(GP_loss,disc_weight,unconnected_gradients=tf.UnconnectedGradients.ZERO)\n",
        "\n",
        "        del tape,Tape,xche,y,Dx,GP_loss\n",
        "        self.opt_GP.apply_gradients(zip(grads,disc_weight))\n",
        "        \n",
        "      gloss = self.gan.train_on_batch(np.random.randn(batch_size,self.z_dim),label_generator)\n",
        "      \n",
        "      if i % sampling_interval == 0:\n",
        "        print(i,losses[-1],gloss)\n",
        "        self.SampleImages(4,4)\n",
        "\n",
        "    self.discriminator.trainable = True\n",
        "    return losses\n",
        " \n",
        "  def RemoveDiscriminator(self):\n",
        "    if self.with_disc == True:\n",
        "      del self.discriminator\n",
        "      self.with_disc = False\n",
        " \n",
        "  def SampleImages(self,x,y):\n",
        "    imgs = self.generator(np.random.randn(x*y,self.z_dim))\n",
        "    fig,ax = plt.subplots(x,y,figsize=(y,x))\n",
        "    if imgs.shape[-1] == 1:\n",
        "      imgs = tf.reshape(imgs,(imgs.shape[0],imgs.shape[1],imgs.shape[2]))\n",
        "      for i in range(x*y):\n",
        "        ax[i%y,i//y].imshow(imgs[i],cmap=\"gray\")\n",
        "    else:\n",
        "      for i in range(x*y):\n",
        "        ax[i%y,i//y].imshow(imgs[i],cmap=\"gray\") \n",
        " \n",
        "  def EM(self,labels,logits):\n",
        "    return ( -tf.reduce_sum(labels * logits) / (tf.reduce_sum(labels) + 1e-10)  + tf.reduce_sum((1. - labels) * (logits)) / (tf.reduce_sum((1. - labels)) + 1e-10))"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-_3fiSxqDI3"
      },
      "source": [
        "#### Monitoring Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYZ5kCbKnH_B"
      },
      "source": [
        "MonitorEMloss class ----->\n",
        " Keras callback for monitoring loss and sampling images if needed.\n",
        "\n",
        "> MonitorEMloss( model,sampling_interval,batch_size,imgs,sample_images) \n",
        "\n",
        "1.   model :: The model on which this callback is applied.\n",
        "2.   sampling_interval :: After how many training steps the loss have to be monitored.\n",
        "3.   batch_size :: The numeber of real and fake images to be sampled for calculating loss.\n",
        "4.   imgs :: Training data images.\n",
        "5.   sample_images :: Boolean, Do images are also to be displayed while monitoring loss.\n",
        "\n",
        "Since, train_step of model.fit uses @tf.function decorator, so the graph that is created makes it harder to save to losses out of the graph, that is why callback is used here instead of directly saving loss inside the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmZtOAseZ_cI"
      },
      "source": [
        "class MonitorEMloss(keras.callbacks.Callback):\n",
        "  def __init__(self,model,sampling_interval,batch_size,imgs,sample_images=False,**kwargs):\n",
        "    self.model = model\n",
        "    self.sampling_interval = sampling_interval\n",
        "    self.counter = 0\n",
        "    self.losses = []\n",
        "    self.batch_size = batch_size\n",
        "    self.imgs = imgs\n",
        "    self.sample_images = sample_images\n",
        " \n",
        "  def on_train_batch_begin(self,batch,logs=None):\n",
        "    self.counter += 1\n",
        "    if self.counter > self.sampling_interval :\n",
        "      self.counter = 0\n",
        "      self.losses.append(model.EM(model.discriminator(np.concatenate([self.imgs[np.random.randint(len(self.imgs),size=self.batch_size)],model(np.random.randn(self.batch_size,model.z_dim))],axis=0)),np.concatenate([np.ones((self.batch_size,1)),np.zeros((self.batch_size,1))],axis=0)).numpy())\n",
        "      if self.sample_images:\n",
        "        model.SampleImages(4,4)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3O8-jPtO3U7"
      },
      "source": [
        "Important Note: Do train for more than 300 iterations and then conclude that the model is stablizing or not from the given hyperparameters because the loss,especially the GP loss is initially fluctuating very much but then stablizes after 300 iterations or more.\n",
        "\n",
        "It may also happen sometimes that the model after converging for 5000 iterations suddenly diverges.In those cases, methods like equalized learning rates and Pixelwise Normalization should be taken into account which reduces the magnitude of gradients."
      ]
    }
  ]
}