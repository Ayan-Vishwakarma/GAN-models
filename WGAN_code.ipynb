{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayan-Vishwakarma/Keras-Implementation-of-Dense-and-DC-NSGAN-WGAN-WGANGP-etc/blob/main/WGAN_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTjeV-Andsb-"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6GGxyTTgbpC"
      },
      "source": [
        "### WGAN Keras model for faster development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpSp4Gv2gjSy"
      },
      "source": [
        "Only discriminator and Generator model are needed to be constructed.The model takes care of the whole WGAN training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCavY9CMgm3D"
      },
      "source": [
        "WGAN -----> Subclass of Keras Model class.\n",
        "\n",
        "Requires a trainable Generator model, a trainable Discriminator model and the dimension of latent space on which generator acts.\n",
        "\n",
        ">fit()\n",
        "\n",
        ">>>Keras Model fit function that requires the images whose distribution has to be learnt.All other working are the same.\n",
        "\n",
        "** Here first n_critic batches of given batch_size are used to train the discriminator and then the last one is used to train the generator.**\n",
        "\n",
        ">training_loop( xt , n_iter , batch_size , sampling_interval )\n",
        "\n",
        ">>>xt :: The numpy ndarray in which images are stored,i.e, the training dataset. shape = (N,H,W,C) \n",
        "\n",
        ">>>n_iter :: The no of iterations to train \n",
        "\n",
        ">>>batch_size :: The batch size used for training \n",
        "\n",
        ">>>sampling_interval :: The interval after which the images are to be sampled \n",
        "\n",
        ">>> return -> EM loss and GP loss after each iteration Note::Here, the training_loop returns the original loss, which fit returns the estimated EM distace,i.e.,the negative of the loss returned by training_loop.\n",
        "\n",
        ">compile( opt_gen , opt_disc , opt_GP , n_critic , clip_value=0.01 )\n",
        "\n",
        ">>> It requires 3 different optmizers:one for generator model, one for discriminator model for reducing EM distance and the third for discriminator for reducing gradient penalty.\n",
        "\n",
        ">>>n_critic is the number of times critic has to be trained\n",
        "\n",
        ">>>clip_value :: The critic's weights will be between -clip_value to clip_value\n",
        "\n",
        "** Here 2 different optimizers are required for discriminator model.**\n",
        "\n",
        ">call(inputs , with_discriminator=None)\n",
        "\n",
        ">>>inputs :: The input to be given to generator.This input is derived from latent space.\n",
        "\n",
        ">>>with_discriminator :: Boolean, If true the outputs are further passed to discriminator.Only valid if discriminator exists.\n",
        "\n",
        ">RemoveDiscriminator(self):: Removes the discriminator from the model leaving behind only the generator model for generating images.Can be used when training is complete.\n",
        "\n",
        ">SampleImages(self , x , y , scale = 1.) :: Sample images from generator. A total of x multiplied by y images are samples displayed in x rows and y columns.\n",
        "\n",
        ">EM(labels,logits) :: Estimates the EM distance given the binary label representing in which class an object belong vs the output of discriminator that best estimates the EM distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqnTE4GDgXcA"
      },
      "source": [
        "Attributes:\n",
        "\n",
        "generator :: The generator model for generating images\n",
        "\n",
        "discriminator :: The critic model which estimates the EM distance between the current generator's distribution and real distribution.\n",
        "\n",
        "z_dim :: Latent space dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaKEmDc4dv3e"
      },
      "source": [
        "class WGAN(keras.models.Model):\n",
        " \n",
        "  def __init__(self,generator,discriminator,z_dim,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.with_disc = True\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "    self.z_dim = z_dim\n",
        "    self.gan = keras.Sequential([generator,discriminator])\n",
        "    assert ((self.gan.layers[0].trainable == True) and (self.gan.layers[1].trainable == True)),\"Generator and Discriminator should be trainable\"\n",
        "    self.generator.build(self.z_dim)\n",
        "    self.discriminator.build(self.generator.output_shape[1:])\n",
        "    class EM(keras.losses.Loss):\n",
        "      def call(self,labels,logits):\n",
        "        return ( -tf.reduce_sum(labels * logits) / (tf.reduce_sum(labels) + 1e-10)  + tf.reduce_sum((1. - labels) * (logits)) / (tf.reduce_sum((1. - labels)) + 1e-10))\n",
        "    self.EM = EM()\n",
        "        \n",
        "  def call(self,inputs,with_discriminator=None):\n",
        "    if with_discriminator and self.with_disc:\n",
        "      return self.gan(inputs)      \n",
        "    else:\n",
        "      return self.generator(inputs)\n",
        " \n",
        "  def compile(self,opt_gen,opt_disc,n_critic=4,clip_value=0.01):\n",
        "    super().compile(optimizer = opt_gen,loss = self.EM)\n",
        "    self.opt_gen = opt_gen\n",
        "    self.opt_disc= opt_disc\n",
        "    self.n_critic = n_critic\n",
        "    self.nc = tf.Variable(n_critic+1,dtype = tf.int32,trainable = False)\n",
        "    self.intervals = tf.Variable(1,dtype = tf.int32,trainable = False)\n",
        "    assert clip_value>0 , \"clip_value should be strictly greater than zero\"\n",
        "    self.clip_value = clip_value\n",
        "    self.__d_loss__ = tf.Variable([0],dtype = tf.float32,trainable = False)\n",
        "    self.__g_loss__ = tf.Variable([0],dtype = tf.float32,trainable = False)\n",
        "  \n",
        "  def train_step(self,imgs):\n",
        "    if isinstance(imgs,tuple):\n",
        "      imgs = data[0]\n",
        "    batch_size = tf.shape(imgs)[0]\n",
        "    \n",
        "    tf.cond(self.intervals != 0, lambda: self.__train_discriminator__(imgs,batch_size),lambda:self.__train_generator__(imgs,batch_size))\n",
        "    self.intervals.assign((self.intervals+1)%self.nc) \n",
        "  \n",
        "    return {\"EM_Distance\":-self.__d_loss__,\"generative_loss\":self.__g_loss__}\n",
        "\n",
        "  def __train_discriminator__(self,imgs,batch_size):\n",
        "    for i in range(self.n_critic):\n",
        "      x = imgs\n",
        "      x_ = self.generator(tf.random.normal((batch_size,self.z_dim)))\n",
        "\n",
        "      with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "        xin = tf.concat([x,x_],axis=0)\n",
        "        yin = tf.concat([tf.ones((batch_size,1)),tf.zeros((batch_size,1))],axis = 0)\n",
        "        loss = self.EM(yin,self.discriminator(xin))\n",
        "\n",
        "      grads = tape.gradient(loss,self.discriminator.trainable_weights)\n",
        "      self.opt_disc.apply_gradients(zip(grads,self.discriminator.trainable_weights))\n",
        "      for j in self.discriminator.weights:\n",
        "        j.assign(tf.clip_by_value(j,clip_value_min= -self.clip_value,clip_value_max= self.clip_value))\n",
        "      del xin,yin,grads\n",
        "      self.__d_loss__.assign(tf.reshape(loss,self.__d_loss__.shape))\n",
        "\n",
        "  def __train_generator__(self,imgs,batch_size):\n",
        "\n",
        "    with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "      xin = tf.random.normal(tf.stack([batch_size,self.z_dim],axis=0))\n",
        "      yin = tf.ones((batch_size,1))\n",
        "      gloss = self.EM(yin,self.gan(xin))\n",
        "    \n",
        "    grads = tape.gradient(gloss,self.generator.trainable_weights)\n",
        "    self.opt_gen.apply_gradients(zip(grads,self.generator.trainable_weights))\n",
        "    self.__g_loss__.assign(tf.reshape(gloss,self.__g_loss__.shape))\n",
        "\n",
        "\n",
        "  def training_loop(self,xt,n_iter,batch_size,sampling_interval):\n",
        "    self.gan.compile( optimizer = self.opt_gen,loss = self.EM)\n",
        "    disc_weight = self.discriminator.trainable_weights\n",
        "    self.discriminator.compile( optimizer = self.opt_disc,loss = self.EM)\n",
        "    self.discriminator.trainable = False\n",
        "    assert self.discriminator.trainable == False\n",
        "\n",
        "    losses = []\n",
        "    for i in range(n_iter):\n",
        "      for j in range(self.n_critic):\n",
        "        ind = np.random.randint(len(xt),size= batch_size)\n",
        "        loss = self.discriminator.train_on_batch(np.concatenate([xt[ind],self.generator(np.random.randn(batch_size,self.z_dim))],axis=0),np.concatenate([np.ones((batch_size,1)),np.zeros((batch_size,1))],axis=0))\n",
        "        for k in disc_weight:\n",
        "          k.assign(tf.clip_by_value(k,clip_value_min= -self.clip_value,clip_value_max= self.clip_value))\n",
        "      self.gan.train_on_batch(np.random.randn(batch_size,self.z_dim),np.ones((batch_size,1)))\n",
        "      losses.append(-loss)\n",
        "      if i % sampling_interval == 0:\n",
        "        print(i,losses[-1])\n",
        "        self.SampleImages(4,4)  \n",
        "    self.discriminator.trainable = True  \n",
        "    return losses\n",
        " \n",
        "  def SampleImages(self,x,y,scale=1.):\n",
        "    imgs = self.generator(np.random.randn(x*y,self.z_dim))\n",
        "    fig,ax = plt.subplots(x,y,figsize=(y*scale,x*scale))\n",
        "    if imgs.shape[-1] == 1:\n",
        "      imgs = tf.reshape(imgs,(imgs.shape[0],imgs.shape[1],imgs.shape[2]))\n",
        "      for i in range(x*y):\n",
        "        ax[i%y,i//y].imshow(imgs[i],cmap=\"gray\")\n",
        "    else:\n",
        "      for i in range(x*y):\n",
        "        ax[i%y,i//y].imshow(imgs[i],cmap=\"gray\") \n",
        "  \n",
        "  def RemoveDiscriminator(self):\n",
        "    if self.with_disc == True:\n",
        "      del self.discriminator\n",
        "      self.with_disc = False"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWC0BiAjgUHu"
      },
      "source": [
        "### MonitorEMloss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP6GSkt1gDZz"
      },
      "source": [
        "MonitorEMloss class -----> Keras callback for monitoring loss and sampling images if needed.\n",
        "\n",
        ">MonitorEMloss( model,sampling_interval,batch_size,imgs,sample_images)\n",
        "\n",
        "1.model :: The model on which this callback is applied.\n",
        "\n",
        "2.sampling_interval :: After how many training steps the loss have to be monitored.\n",
        "\n",
        "3.batch_size :: The numeber of real and fake images to be sampled for calculating loss.\n",
        "\n",
        "4.imgs :: Training data images.\n",
        "\n",
        "5.sample_images :: Boolean, Do images are also to be displayed while monitoring loss.\n",
        "\n",
        "Since, train_step of model.fit uses @tf.function decorator, so the graph that is created makes it harder to save to losses out of the graph, that is why callback is used here instead of directly saving loss inside the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2yd1aFffdOg"
      },
      "source": [
        "class MonitorEMloss(keras.callbacks.Callback):\n",
        "  def __init__(self,model,sampling_interval,batch_size,imgs,sample_images=False,**kwargs):\n",
        "    self.model = model\n",
        "    self.sampling_interval = sampling_interval\n",
        "    self.counter = 0\n",
        "    self.losses = []\n",
        "    self.batch_size = batch_size\n",
        "    self.imgs = imgs\n",
        "    self.sample_images = sample_images\n",
        " \n",
        "  def on_train_batch_begin(self,batch,logs=None):\n",
        "    self.counter += 1\n",
        "    if self.counter > self.sampling_interval :\n",
        "      self.counter = 0\n",
        "      self.losses.append(-model.EM(model.discriminator(np.concatenate([self.imgs[np.random.randint(len(self.imgs),size=self.batch_size)],model(np.random.randn(self.batch_size,model.z_dim))],axis=0)),np.concatenate([np.ones((self.batch_size,1)),np.zeros((self.batch_size,1))],axis=0)).numpy())\n",
        "      if self.sample_images:\n",
        "        model.SampleImages(4,4)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOAkj8xGjEBx"
      },
      "source": [
        "Note: The right discriminator if found by gradient descent methodology.So initially loss increases and then after finding the optimal critic that estimates the Wasserstein-1 distance, loss starts to decrease.So,train for at least 300 iterations before concluding that the given hyperparamets stablizes the model or not."
      ]
    }
  ]
}