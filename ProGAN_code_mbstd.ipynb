{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled15.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TqxYRym7KcIMmubrTtan-WyDMYoUKzoZ",
      "authorship_tag": "ABX9TyNT8soLi3IyWVtZQv7ECiK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayan-Vishwakarma/Keras-Implementation-of-Dense-and-DC-NSGAN-WGAN-WGANGP-etc/blob/main/ProGAN_code_mbstd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xUHmi_ystAB"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2c1l_PpsRkv"
      },
      "source": [
        "### Progressive Growing GAN's with MiniBatch Standard Deviation for preventing Mode Collapse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl5Xs2Vnt5Tx"
      },
      "source": [
        "To reduce the effects of mode collapse in GANs, the information about batch is provided to the discriminator so that it can not only discriminate on the basis of images but also by the variation in batch of images. \n",
        "\n",
        "In minibatch standard deviation, the batch is reduced by standard deviation along the batch_size axis of real/generated sample, so that it generates a image whose per-pixel value represents the standard deviation of that pixel in the batch. The mean std is calculated from the new image and then tiled and  concatenated to the last layer of image such that now the image is with 4 channels,last of which represents the mean std along the batch.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQqZ0ntFKdBP"
      },
      "source": [
        "PGGAN( initial_generator_block , initial_discriminator_block , z_dim , image_shape , extract_dims , trainer = \"NSGAN\" )\n",
        "\n",
        "> initial_discriminator_block : Initial discriminator block [Model] which takes in z_dim vector and returns image_shape's height * image_shape's width * out_channels.\n",
        ">> The images output passes though tanh activation and so are between -1 to 1 value.So the **training images should be initially rescaled between -1 to 1**.\n",
        "\n",
        ">>The initial_discrimiator_block should take images with **1 channel more than given by extract_dims** to take account for the standard deviation.All other process are same.The MiniBatch Std is accounted only for the initial_discriminator_block and other added functional/sequential block do not take account of the minibatch standard deviation.\n",
        "\n",
        "> initial_generator_block : Initial generator block[Model] which takes in z_dim vector and returns image_shape dimensional image. The input will be image_shape's height * image_shape's width * extract_dims and output will be a scalar.\n",
        ">> For NSGAN trainer, output should have **sigmoid** activation.\n",
        "\n",
        ">> For WGAN_GP trainer, output should **not** have any activation.\n",
        "\n",
        "> z_dim : Latent space dimension.\n",
        "\n",
        "> image_shape : Initial resolution of images.\n",
        "\n",
        "> extract_dims : Number of feature maps the FROM RGB block extracts.\n",
        "\n",
        ">trainer : Training model.Either NSGAN or WGAN_GP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13eiSRi1NZEh"
      },
      "source": [
        "Attributes:\n",
        "\n",
        ">generator\n",
        "\n",
        ">discriminator\n",
        "\n",
        ">extract_dims\n",
        "\n",
        ">z_dim\n",
        "\n",
        ">image_shape\n",
        "\n",
        "\n",
        "Based on which trainer used:\n",
        "\n",
        ">NSGAN\n",
        "\n",
        ">WGAN_GP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d6bKC1ot1qs"
      },
      "source": [
        "###### Auxillary layers to help PGGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azCAkg_Jsv3K"
      },
      "source": [
        "class MiniBatchStd(keras.layers.Layer):\n",
        "  def __init__(self,image_shape,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.image_shape = tf.constant(image_shape,dtype=tf.int32)\n",
        "  def call(self,inputs):\n",
        "    shape = tf.concat([tf.reshape(tf.shape(inputs)[0],(1,)),self.image_shape],axis=0)\n",
        "    return tf.ones(shape,tf.float32)*tf.math.reduce_mean(tf.math.reduce_std(inputs,axis=0,keepdims=False),keepdims=False)\n",
        "  def compute_output_shape(self,input_shape):\n",
        "    return self.image_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYlpUsXDs-O3"
      },
      "source": [
        "class MergeLayer(keras.layers.Layer):\n",
        "  def __init__(self,n_intervals,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.alpha = tf.Variable([0.],trainable=False)\n",
        "    self.n_intervals = tf.Variable([n_intervals],dtype=tf.float32,trainable=False)\n",
        "  def call(self,inputs):\n",
        "    self.alpha.assign(tf.clip_by_value(self.alpha + tf.math.reciprocal(self.n_intervals),clip_value_min=0.,clip_value_max = 1.))\n",
        "    return self.alpha * inputs[0] + (1 - self.alpha) * inputs[1]\n",
        "  def compute_output_shape(self,input_shape):\n",
        "    return input_shape\n",
        "  def get_config(self):\n",
        "    return {\"name\":self.name,\"alpha\":self.alpha,\"n_intervals\":self.n_intervals}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-xyH-f7st84"
      },
      "source": [
        "###### PGGAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797je7OOChI-"
      },
      "source": [
        "class PGGAN():\n",
        "  def __init__(self,initial_generator_block,initial_discriminator_block,z_dim,image_shape,trainer=\"NSGAN\",**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.z_dim = z_dim\n",
        "    self.extract_dims = initial_discriminator_block.input_shape[-1] - 1\n",
        "    self.image_shape = image_shape\n",
        "    self.initial_shape = list(image_shape[0:2]) + [1]\n",
        "\n",
        "    ######################################   Initial Generator   #####################################################\n",
        "\n",
        "    xin = keras.layers.Input((z_dim))\n",
        "    x = initial_generator_block(xin)\n",
        "    x = keras.layers.Conv2D(3,(1,1),(1,1),padding=\"same\",activation=\"tanh\")(x)\n",
        "    self.generator = keras.models.Model(inputs=[xin],outputs=[x])\n",
        "\n",
        "    ######################################   Initial Discriminator   #################################################\n",
        "\n",
        "    x2in = keras.layers.Input(self.initial_shape)\n",
        "    x1in = keras.layers.Input(image_shape)\n",
        "    x1 = keras.layers.Conv2D(self.extract_dims,(3,3),(1,1),padding=\"same\")(x1in)\n",
        "    x1 = keras.layers.LeakyReLU(0.05)(x1)\n",
        "    x = tf.keras.layers.Concatenate(axis=-1)([x1,x2in])\n",
        "    x = initial_discriminator_block(x)\n",
        "    self.discriminator = keras.models.Model(inputs=[x1in,x2in],outputs=[x])\n",
        "\n",
        "    ###################################  Trainer  #####################################################\n",
        "    self.trainer = trainer.upper()\n",
        "    assert self.trainer == \"NSGAN\" or self.trainer == \"WGAN_GP\",\"trainer should be NSGAN or WGAN_GP\"\n",
        "    if self.trainer == \"NSGAN\":\n",
        "      self.NSGAN = NSGAN(self.generator,self.discriminator,self.z_dim,self.initial_shape)\n",
        "    elif self.trainer == \"WGAN_GP\":\n",
        "      self.WGAN_GP = WGAN_GP(self.generator,self.discriminator,self.z_dim,self.initial_shape)\n",
        "\n",
        "  def ProgressGAN(self,add_functional_generator,add_functional_discriminator,multiplier,n_intervals,extract_dims=None):\n",
        "    image_shape = self.image_shape\n",
        "    discriminator = self.discriminator\n",
        "    generator = self.generator\n",
        "\n",
        "    assert self.extract_dims == add_functional_discriminator.output_shape[-1] , \"The number of feature maps extracted by newly added discriminator should match with the input feature maps required by the previously trained discriminator model\"\n",
        "\n",
        "    try:\n",
        "      ####################################  Progressing Discriminator   ###############################################\n",
        "\n",
        "      self.rdl = []\n",
        "      self.extract_dims = add_functional_discriminator.input_shape[-1]\n",
        "\n",
        "      self.image_shape = self.image_shape * np.concatenate([np.array(multiplier,dtype=np.int32),np.array([1],dtype=np.int32)],axis=0)\n",
        "      xin = keras.layers.Input(self.image_shape)\n",
        "      y = xin\n",
        "\n",
        "      layer = keras.layers.AveragePooling2D(multiplier)\n",
        "      self.rdl.append(layer.name)\n",
        "      x = layer(xin)\n",
        "      for i in self.discriminator.layers[1:3]:\n",
        "        self.rdl.append(i.name)\n",
        "        x = i(x)\n",
        "\n",
        "      x2in = keras.layers.Input(self.initial_shape)\n",
        "      self.rdl.append(x2in.name)\n",
        "      \n",
        "      y = keras.layers.Conv2D(self.extract_dims,(3,3),(1,1),padding='same')(y)\n",
        "      y = keras.layers.LeakyReLU(0.05)(y)\n",
        "      y = add_functional_discriminator(y)\n",
        "      \n",
        "      if self.trainer == \"WGAN_GP\":\n",
        "        layer = MergeLayer(int(n_intervals * (1+2*self.WGAN_GP.n_critic)/(self.WGAN_GP.n_critic + 1)))\n",
        "      else:\n",
        "        layer = MergeLayer(int((4*n_intervals)/3))\n",
        "      self.rdl.append(layer.name)\n",
        "      x = layer([y,x])\n",
        "\n",
        "      for i in self.discriminator.layers[3:-3]:\n",
        "        x = i(x)\n",
        "\n",
        "      self.sdl = []\n",
        "      layer = keras.layers.Concatenate(axis=-1) \n",
        "      self.sdl.append(layer.name)\n",
        "      x = layer([x,x2in])\n",
        "      x = self.discriminator.layers[-1](x)\n",
        "\n",
        "      self.discriminator = keras.models.Model(inputs=[xin,x2in],outputs = [x])\n",
        "\n",
        "      ##########################################  Progressing Generator  ################################################\n",
        "\n",
        "      xin = keras.layers.Input((self.z_dim))\n",
        "      x = xin\n",
        "      self.rgl = []\n",
        "      for i in self.generator.layers[1:-1]:\n",
        "        x = i(x)\n",
        "      y = x\n",
        "      \n",
        "      x = add_functional_generator(x)\n",
        "      x = keras.layers.Conv2D(3,(1,1),(1,1),padding=\"same\",activation=\"tanh\")(x)\n",
        "\n",
        "      layer = keras.layers.UpSampling2D(multiplier)\n",
        "      y = layer(y)\n",
        "      self.rgl.append(layer.name)\n",
        "      layer = self.generator.layers[-1]\n",
        "      self.rgl.append(layer.name)\n",
        "      y = layer(y)\n",
        "      layer = MergeLayer(n_intervals)\n",
        "      self.rgl.append(layer.name)\n",
        "      z = layer([x,y])\n",
        "\n",
        "      self.generator = keras.models.Model(inputs=[xin],outputs=[z])\n",
        "\n",
        "    except Exception as e:\n",
        "      self.discriminator = discriminator\n",
        "      self.generator = generator\n",
        "      self.image_shape = image_shape\n",
        "      print(e)\n",
        "      return \n",
        "    ###################################  Trainer  #####################################################\n",
        "    if self.trainer == \"NSGAN\":\n",
        "      self.NSGAN = NSGAN(self.generator,self.discriminator,self.z_dim,self.initial_shape)\n",
        "    elif self.trainer == \"WGAN_GP\":\n",
        "      self.WGAN_GP = WGAN_GP(self.generator,self.discriminator,self.z_dim,self.initial_shape)\n",
        "\n",
        "  def StreamlineGAN(self):\n",
        "\n",
        "    ###################################   Streamline Generator   #######################################\n",
        "\n",
        "    xin = keras.layers.Input((self.z_dim))\n",
        "    x = xin\n",
        "    for i in self.generator.layers[1:]:\n",
        "      if i.name not in self.rgl:\n",
        "        x = i(x)\n",
        "    self.generator = keras.models.Model(inputs=[xin],outputs=[x])\n",
        "\n",
        "    ###################################   Streamline Discriminator   ###################################\n",
        "\n",
        "    xin = keras.layers.Input(self.image_shape)\n",
        "    x = xin\n",
        "    x2in = keras.layers.Input(self.initial_shape)\n",
        "    for i in self.discriminator.layers[1:]:\n",
        "      if i.name in self.sdl:\n",
        "        x = i([x,x2in])\n",
        "        continue\n",
        "      if i.name not in self.rdl:\n",
        "        x = i(x)\n",
        "    self.discriminator = keras.models.Model(inputs=[xin,x2in],outputs=[x])\n",
        "\n",
        "\n",
        "    ###################################  Trainer  #####################################################\n",
        "    if self.trainer == \"NSGAN\":\n",
        "      self.NSGAN = NSGAN(self.generator,self.discriminator,self.z_dim,self.initial_shape)\n",
        "    elif self.trainer == \"WGAN_GP\":\n",
        "      self.WGAN_GP = WGAN_GP(self.generator,self.discriminator,self.z_dim,self.initial_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnB5McZss0kM"
      },
      "source": [
        "## NSGAN and WGAN_GP models that takes into Minibatch standard deviation into account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suo__AGYCoxv"
      },
      "source": [
        "class NSGAN(keras.models.Model):\n",
        "  def __init__(self,generator,discriminator,z_dim,initial_shape,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.with_disc = True\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "    self.z_dim = z_dim\n",
        "    xin = keras.layers.Input((z_dim,))\n",
        "    x = self.generator(xin)\n",
        "    x1 = x\n",
        "    x1 = MiniBatchStd(initial_shape)(x1)\n",
        "    y = self.discriminator([x,x1])\n",
        "    self.initial_shape = initial_shape\n",
        "    self.gan = keras.models.Model(inputs = [xin],outputs=[y])\n",
        "    self.gm = keras.metrics.BinaryAccuracy(name=\"binary_accuracy_generator\")\n",
        "    self.dm = keras.metrics.BinaryAccuracy(name=\"binary_accuracy_discriminator\")\n",
        "    assert ((self.gan.layers[0].trainable == True) and (self.gan.layers[1].trainable == True)),\"Generator and Discriminator should be trainable\"\n",
        " \n",
        "  def compile(self,opt_gen,opt_disc):\n",
        "    super().compile(optimizer = opt_gen,loss = \"binary_crossentropy\")\n",
        "    self.opt_gen = opt_gen\n",
        "    self.opt_disc= opt_disc\n",
        " \n",
        "  def train_step(self,imgs):\n",
        "    if isinstance(imgs,tuple):\n",
        "      imgs = data[0]\n",
        "    \n",
        "    batch_size = tf.shape(imgs)[0]\n",
        "\n",
        "    x = [imgs,MiniBatchStd(self.initial_shape)(imgs)]\n",
        "    x_ = self.generator(tf.random.normal((batch_size,self.z_dim)))\n",
        "    x_ = [x_,MiniBatchStd(self.initial_shape)(x_)]\n",
        "\n",
        "    with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "      xin = [tf.concat([x[0],x_[0]],axis=0),tf.concat([x[1],x_[1]],axis=0)]\n",
        "      yin = tf.concat([tf.ones((batch_size,1)),tf.zeros((batch_size,1))],axis = 0)\n",
        "      self.dm.update_state(yin,self.discriminator(xin))\n",
        "      loss = keras.losses.binary_crossentropy(yin,self.discriminator(xin))\n",
        "\n",
        "    grads = tape.gradient(loss,self.discriminator.trainable_weights)\n",
        "    self.opt_disc.apply_gradients(zip(grads,self.discriminator.trainable_weights))\n",
        "    del xin,yin,grads\n",
        "\n",
        "    with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "      xin = tf.random.normal(tf.stack([batch_size,self.z_dim],axis=0))\n",
        "      yin = tf.ones((batch_size,1))\n",
        "      self.gm.update_state(yin,self.gan(xin))\n",
        "      gloss = keras.losses.binary_crossentropy(yin,self.gan(xin))\n",
        "    \n",
        "    grads = tape.gradient(gloss,self.generator.trainable_weights)\n",
        "    self.opt_gen.apply_gradients(zip(grads,self.generator.trainable_weights))\n",
        " \n",
        "    return {\"Discriminator_loss\":loss,\"Generator_loss\":gloss,self.gm.name:self.gm.result(),self.dm.name:self.dm.result()}\n",
        " \n",
        "  def SampleImages(self,x,y):\n",
        "    imgs = self.generator(np.random.randn(x*y,self.z_dim))\n",
        "    fig,ax = plt.subplots(x,y,figsize=(y*2,x*2))\n",
        "    if imgs.shape[-1] == 1:\n",
        "      imgs = tf.reshape(imgs,(imgs.shape[0],imgs.shape[1],imgs.shape[2]))\n",
        "      for i in range(x*y):\n",
        "        ax[i%y,i//y].imshow(imgs[i]/2 + 0.5,cmap=\"gray\")\n",
        "    else:\n",
        "      for i in range(x*y):\n",
        "        ax[i%y,i//y].imshow(imgs[i]/2 + 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn2_jDZV8Bfn"
      },
      "source": [
        "class WGAN_GP(keras.models.Model):\n",
        " \n",
        "  def __init__(self,generator,discriminator,z_dim,initial_shape,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.with_disc = True\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "    self.z_dim = z_dim\n",
        "    xin = keras.layers.Input((z_dim,))\n",
        "    x = self.generator(xin)\n",
        "    x1 = x\n",
        "    x1 = MiniBatchStd(initial_shape)(x1)\n",
        "    y = self.discriminator([x,x1])\n",
        "    self.initial_shape = initial_shape\n",
        "    self.gan = keras.models.Model(inputs = [xin],outputs=[y])\n",
        "    assert ((self.gan.layers[0].trainable == True) and (self.gan.layers[1].trainable == True)),\"Generator and Discriminator should be trainable\"\n",
        " \n",
        "  def compile(self,opt_gen,opt_disc,opt_GP,n_critic,lmbda=10):\n",
        "    super().compile(optimizer = opt_gen,loss = self.EM)\n",
        "    self.opt_gen = opt_gen\n",
        "    self.opt_disc= opt_disc\n",
        "    self.opt_GP = opt_GP\n",
        "    self.n_critic = n_critic\n",
        "    self.nc = tf.Variable(n_critic+1,dtype = tf.int32,trainable = False)\n",
        "    self.intervals = tf.Variable(1,dtype = tf.int32,trainable = False)\n",
        "    assert ( lmbda > 0 ),\"lambda value should be strictly greater than 0\"\n",
        "    self.lmbda = lmbda\n",
        "    self.__d_loss__ = tf.Variable([0],dtype = tf.float32,trainable = False)\n",
        "    self.__g_loss__ = tf.Variable([0],dtype = tf.float32,trainable = False)\n",
        "    self.__GP_loss__ = tf.Variable([0],dtype = tf.float32,trainable = False)\n",
        " \n",
        "  def train_step(self,imgs):\n",
        "    if isinstance(imgs,tuple):\n",
        "      imgs = data[0]\n",
        "    batch_size =  tf.shape(imgs)[0]\n",
        "\n",
        "    tf.cond(self.intervals != 0, lambda: self.__train_discriminator__(imgs,batch_size),lambda:self.__train_generator__(imgs,batch_size))\n",
        "    self.intervals.assign((self.intervals+1)%self.nc) \n",
        "    return {\"EM_Distance\":-self.__d_loss__,\"GP_loss\":self.__GP_loss__,\"generative_loss\":self.__g_loss__}\n",
        "\n",
        "  def __train_discriminator__(self,imgs,batch_size):\n",
        "    x = [imgs,MiniBatchStd(self.initial_shape)(imgs)]\n",
        "    x_ = self.generator(tf.random.normal((batch_size,self.z_dim)))\n",
        "    x_ = [x_,MiniBatchStd(self.initial_shape)(x_)]\n",
        "\n",
        "    with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "      xin = [tf.concat([x[0],x_[0]],axis=0),tf.concat([x[1],x_[1]],axis=0)]\n",
        "      yin = tf.concat([tf.ones((batch_size,1)),tf.zeros((batch_size,1))],axis = 0)\n",
        "      loss = self.EM(yin,self.discriminator(xin))\n",
        "\n",
        "    grads = tape.gradient(loss,self.discriminator.trainable_weights)#\n",
        "    self.opt_disc.apply_gradients(zip(grads,self.discriminator.trainable_weights))#\n",
        "    del xin,yin,grads\n",
        "\n",
        "    t = tf.random.uniform((batch_size,1,1,1))\n",
        "    xche = t*x[0] + (1-t)*x_[0]\n",
        "\n",
        "    with tf.GradientTape(watch_accessed_variables=True,persistent = True) as Tape:\n",
        "      Tape.watch(xche)\n",
        "      with tf.GradientTape(watch_accessed_variables=True,persistent=True) as tape:\n",
        "        tape.watch(xche)\n",
        "        y =  self.discriminator([xche,MiniBatchStd(self.initial_shape)(xche)])\n",
        "      Dx = tape.gradient(y,xche)\n",
        "      GP_loss = self.lmbda * tf.math.reduce_mean((tf.math.reduce_euclidean_norm(Dx,axis=[1,2,3]) - 1.)**2)\n",
        "\n",
        "    grads = Tape.gradient(GP_loss,self.discriminator.trainable_weights,unconnected_gradients=tf.UnconnectedGradients.ZERO)#\n",
        "\n",
        "    del tape,Tape,xche,y,Dx,x,x_\n",
        "    self.opt_GP.apply_gradients(zip(grads,self.discriminator.trainable_weights))#\n",
        "    self.opt_GP.apply_gradients(zip(grads,self.discriminator.trainable_weights))\n",
        "    self.__d_loss__.assign(tf.reshape(loss,self.__d_loss__.shape))\n",
        "    self.__GP_loss__.assign(tf.reshape(GP_loss,self.__GP_loss__.shape))\n",
        " \n",
        "  def __train_generator__(self,imgs,batch_size):\n",
        "    with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "      xin = tf.random.normal(tf.stack([batch_size,self.z_dim],axis=0))\n",
        "      yin = tf.ones((batch_size,1))\n",
        "      gloss = self.EM(yin,self.gan(xin))\n",
        "    \n",
        "    grads = tape.gradient(gloss,self.generator.trainable_weights)\n",
        "    self.opt_gen.apply_gradients(zip(grads,self.generator.trainable_weights))\n",
        "    self.opt_gen.apply_gradients(zip(grads,self.generator.trainable_weights))\n",
        "    self.__g_loss__.assign(tf.reshape(gloss,self.__g_loss__.shape))\n",
        " \n",
        " \n",
        "  def SampleImages(self,x,y,scale = 1.):\n",
        "    imgs = self.generator(np.random.randn(x*y,self.z_dim))\n",
        "    fig,ax = plt.subplots(x,y,figsize=(y*scale,x*scale))\n",
        "    if imgs.shape[-1] == 1:\n",
        "      imgs = tf.reshape(imgs,(imgs.shape[0],imgs.shape[1],imgs.shape[2]))\n",
        "      for i in range(x*y):\n",
        "        ax[i%y,i//y].imshow(imgs[i]/2 + 0.5,cmap=\"gray\")\n",
        "    else:\n",
        "      for i in range(x*y):\n",
        "        ax[i%y,i//y].imshow(imgs[i]/2 + 0.5) \n",
        " \n",
        "  def EM(self,labels,logits):\n",
        "    return ( -tf.reduce_sum(labels * logits) / (tf.reduce_sum(labels) + 1e-10)  + tf.reduce_sum((1. - labels) * (logits)) / (tf.reduce_sum((1. - labels)) + 1e-10))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}